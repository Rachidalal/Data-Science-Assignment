{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b43e63d",
      "metadata": {
        "id": "2b43e63d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import spacy\n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "from matplotlib import pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f393d6c0",
      "metadata": {
        "id": "f393d6c0",
        "outputId": "70374d13-cf55-46d0-afec-419ed1ed26a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@kunalb11 Im an alien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@joerogan @Spotify Great interview!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@gtera27 Doge is underestimated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>1995</td>\n",
              "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1996</td>\n",
              "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1997</td>\n",
              "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1998</td>\n",
              "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1999</td>\n",
              "      <td>Progress update August 28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1999 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                                               Text\n",
              "0              1                             @kunalb11 Im an alien\n",
              "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
              "2              3                @joerogan @Spotify Great interview!\n",
              "3              4                    @gtera27 Doge is underestimated\n",
              "4              5  @teslacn Congratulations Tesla China for amazi...\n",
              "...          ...                                                ...\n",
              "1994        1995  @flcnhvy True, it sounds so surreal, but the n...\n",
              "1995        1996  @PPathole Make sure to read ur terms &amp; con...\n",
              "1996        1997                @TeslaGong @PPathole Samwise Gamgee\n",
              "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
              "1998        1999                          Progress update August 28\n",
              "\n",
              "[1999 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data=pd.read_csv(\"Elon_musk.csv\", encoding = 'unicode_escape')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b15793",
      "metadata": {
        "id": "d0b15793"
      },
      "outputs": [],
      "source": [
        "data = [Text.strip() for Text in data.Text]\n",
        "data = [Text for Text in data if Text]\n",
        "data[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02bece63",
      "metadata": {
        "id": "02bece63"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(data)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b56de1a6",
      "metadata": {
        "id": "b56de1a6"
      },
      "outputs": [],
      "source": [
        "no_punc_text = text.translate(str.maketrans('','',string.punctuation))\n",
        "no_punc_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd9f6cf",
      "metadata": {
        "id": "efd9f6cf"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "one_block = data[2]\n",
        "doc_block = nlp(one_block)\n",
        "spacy.displacy.render(doc_block, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dda9ff",
      "metadata": {
        "id": "58dda9ff"
      },
      "outputs": [],
      "source": [
        "one_block\n",
        "for token in doc_block[0:20]:\n",
        "    print(token, token.pos_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34834b13",
      "metadata": {
        "id": "34834b13"
      },
      "outputs": [],
      "source": [
        "nouns_verbs = [token.text for token in doc_block if token.pos_ in ('NOUN', 'VERB')]\n",
        "print(nouns_verbs[5:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340bc324",
      "metadata": {
        "id": "340bc324"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9f3c2e",
      "metadata": {
        "id": "ab9f3c2e"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "text_tokens=word_tokenize(no_punc_text)\n",
        "print(text_tokens[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cd8227b",
      "metadata": {
        "id": "9cd8227b"
      },
      "outputs": [],
      "source": [
        "len(text_tokens)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "my_stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67bd8de8",
      "metadata": {
        "id": "67bd8de8"
      },
      "outputs": [],
      "source": [
        "my_stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeffce90",
      "metadata": {
        "id": "aeffce90"
      },
      "outputs": [],
      "source": [
        "my_stop_words.append('would')\n",
        "my_stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1bff71c",
      "metadata": {
        "id": "d1bff71c"
      },
      "outputs": [],
      "source": [
        "my_stop_words.append('himself')\n",
        "my_stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef46143",
      "metadata": {
        "id": "2ef46143"
      },
      "outputs": [],
      "source": [
        "no_stop_tokens = [word for word in text_tokens if not word in my_stop_words]\n",
        "print(no_stop_tokens[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24db1a2a",
      "metadata": {
        "id": "24db1a2a"
      },
      "outputs": [],
      "source": [
        "lower_words = [Text.lower() for Text in no_stop_tokens]\n",
        "print(lower_words[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "467b5ccb",
      "metadata": {
        "id": "467b5ccb"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps =PorterStemmer()\n",
        "stemmed_tokens = [ps.stem(word) for word in lower_words]\n",
        "print(stemmed_tokens[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241f317e",
      "metadata": {
        "id": "241f317e"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e59880",
      "metadata": {
        "id": "b9e59880"
      },
      "outputs": [],
      "source": [
        "doc = nlp(' '.join(no_stop_tokens))\n",
        "print(doc[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300c6694",
      "metadata": {
        "id": "300c6694"
      },
      "outputs": [],
      "source": [
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(lemmas[0:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb5b2c2",
      "metadata": {
        "id": "4bb5b2c2"
      },
      "outputs": [],
      "source": [
        "len(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b36ccd",
      "metadata": {
        "id": "05b36ccd"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd739a8",
      "metadata": {
        "id": "4dd739a8"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a79308d8",
      "metadata": {
        "id": "a79308d8"
      },
      "outputs": [],
      "source": [
        "print(bow_matrix.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e1d136",
      "metadata": {
        "id": "86e1d136"
      },
      "outputs": [],
      "source": [
        "bow_matrix.toarray().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1561aa",
      "metadata": {
        "id": "5f1561aa"
      },
      "outputs": [],
      "source": [
        "vectorizer_ngram = CountVectorizer(analyzer='word',ngram_range=(1,2),max_features = 100)\n",
        "\n",
        "bow_matrix_ngram = vectorizer_ngram.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f097d9",
      "metadata": {
        "id": "35f097d9"
      },
      "outputs": [],
      "source": [
        "print(bow_matrix_ngram.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2196473",
      "metadata": {
        "id": "c2196473"
      },
      "outputs": [],
      "source": [
        "bow_matrix_ngram.toarray().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e36a344",
      "metadata": {
        "id": "3e36a344"
      },
      "outputs": [],
      "source": [
        "afinn = pd.read_csv(\"C:/Users/Rishi/Downloads/Afinn.csv\", sep=',', encoding='latin-1')\n",
        "afinn.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aeae6be",
      "metadata": {
        "id": "2aeae6be"
      },
      "outputs": [],
      "source": [
        "afinn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "009b9b71",
      "metadata": {
        "id": "009b9b71"
      },
      "outputs": [],
      "source": [
        "from nltk import tokenize\n",
        "sentences = tokenize.sent_tokenize(' '.join(data))\n",
        "sentences[5:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad01dce",
      "metadata": {
        "id": "4ad01dce"
      },
      "outputs": [],
      "source": [
        "sent_df = pd.DataFrame(sentences, columns=['sentence'])\n",
        "sent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b12d157",
      "metadata": {
        "id": "3b12d157"
      },
      "outputs": [],
      "source": [
        "affinity_scores = afinn.set_index('word')['value'].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3967b733",
      "metadata": {
        "id": "3967b733"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "sentiment_lexicon = affinity_scores\n",
        "\n",
        "def calculate_sentiment(text: str = None):\n",
        "    sent_score = 0\n",
        "    if text:\n",
        "        sentence = nlp(text)\n",
        "        for word in sentence:\n",
        "            sent_score += sentiment_lexicon.get(word.lemma_, 0)\n",
        "    return sent_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ca3dcc",
      "metadata": {
        "id": "68ca3dcc"
      },
      "outputs": [],
      "source": [
        "calculate_sentiment(text = 'amazing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54141441",
      "metadata": {
        "id": "54141441"
      },
      "outputs": [],
      "source": [
        "sent_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705887a2",
      "metadata": {
        "id": "705887a2"
      },
      "outputs": [],
      "source": [
        "sent_df['sentiment_value'] = sent_df['sentence'].apply(calculate_sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33a0c589",
      "metadata": {
        "id": "33a0c589"
      },
      "outputs": [],
      "source": [
        "sent_df['word_count'] = sent_df['sentence'].str.split().apply(len)\n",
        "sent_df['word_count'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb67d5c4",
      "metadata": {
        "id": "eb67d5c4"
      },
      "outputs": [],
      "source": [
        "sent_df.sort_values(by='sentiment_value').tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade9ebeb",
      "metadata": {
        "id": "ade9ebeb"
      },
      "outputs": [],
      "source": [
        "sent_df['sentiment_value'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67cf3a85",
      "metadata": {
        "id": "67cf3a85"
      },
      "outputs": [],
      "source": [
        "sent_df[sent_df['sentiment_value']<=0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf9782f",
      "metadata": {
        "id": "0bf9782f"
      },
      "outputs": [],
      "source": [
        "sent_df[sent_df['sentiment_value']>=17].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5994c0e0",
      "metadata": {
        "id": "5994c0e0"
      },
      "outputs": [],
      "source": [
        "sent_df['index']=range(0,len(sent_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce61a9d",
      "metadata": {
        "id": "5ce61a9d"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.distplot(sent_df['sentiment_value'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9acc26",
      "metadata": {
        "id": "bf9acc26"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "sns.lineplot(y='sentiment_value',x='index',data=sent_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbb0904",
      "metadata": {
        "id": "cfbb0904"
      },
      "outputs": [],
      "source": [
        "sent_df.plot.scatter(x='word_count', y='sentiment_value', figsize=(8,8), title='Sentence sentiment value to sentence word count')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}